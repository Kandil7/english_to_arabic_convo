{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOzUK2nP3E0IHhuJ+KTQru",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kandil7/english_to_arabic_convo/blob/main/english_to_arabic_conversation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDigqk2QUjnC"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch torchaudio transformers gradio pydub\n",
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download sample audio\n",
        "!wget -q https://www.sound-effects.in/audio/samples/10610/english-conversation.mp3 -O sample_english.mp3\n",
        "!ffmpeg -y -i sample_english.mp3 -ac 1 -ar 16000 sample_english.wav"
      ],
      "metadata": {
        "id": "sBRwNHAvWY2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load models\n",
        "import torch\n",
        "from transformers import MarianMTModel, MarianTokenizer, AutoModelForCausalLM, AutoTokenizer\n",
        "import whisper\n",
        "\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "translation_tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\")\n",
        "translation_model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-ar\")\n",
        "convo_tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/aragpt2\")\n",
        "convo_model = AutoModelForCausalLM.from_pretrained(\"aubmindlab/aragpt2\")\n"
      ],
      "metadata": {
        "id": "x9uhGLoEWcGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define functions\n",
        "def transcribe_audio(audio_path):\n",
        "    result = whisper_model.transcribe(audio_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "def translate_to_arabic(text):\n",
        "    inputs = translation_tokenizer(text, return_tensors=\"pt\", padding=True)\n",
        "    outputs = translation_model.generate(**inputs)\n",
        "    return translation_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def generate_conversation(prompt, max_length=50):\n",
        "    inputs = convo_tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = convo_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return convo_tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "XutrZ8eQWjUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test the pipeline\n",
        "english_text = transcribe_audio(\"sample_english.wav\")\n",
        "print(\"English Transcript:\", english_text)\n",
        "\n",
        "arabic_text = translate_to_arabic(english_text)\n",
        "print(\"Translated Arabic:\", arabic_text)\n",
        "\n",
        "conversational_arabic = generate_conversation(arabic_text)\n",
        "print(\"Conversational Arabic:\", conversational_arabic)\n"
      ],
      "metadata": {
        "id": "8k8p1SZ6W8Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradio interface\n",
        "import gradio as gr\n",
        "\n",
        "def process_audio(audio_file):\n",
        "    english_text = transcribe_audio(audio_file)\n",
        "    arabic_text = translate_to_arabic(english_text)\n",
        "    conversational_arabic = generate_conversation(arabic_text)\n",
        "    return {\n",
        "        \"English Transcript\": english_text,\n",
        "        \"Translated Arabic\": arabic_text,\n",
        "        \"Conversational Arabic\": conversational_arabic\n",
        "    }\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=process_audio,\n",
        "    inputs=gr.Audio(type=\"filepath\", label=\"Upload English Audio\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"English Transcript\"),\n",
        "        gr.Textbox(label=\"Translated Arabic\"),\n",
        "        gr.Textbox(label=\"Conversational Arabic\")\n",
        "    ],\n",
        "    examples=[[\"sample_english.wav\"]],\n",
        "    title=\"English to Arabic Conversational AI\"\n",
        ")\n",
        "\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "id": "zyNwbNMKXBJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Key Notes\n",
        "\n",
        "##GPU Recommendation :\n",
        " Use a GPU runtime for faster inference (especially for Whisper and AraGPT2).\n",
        "## Sample Audio :\n",
        "The provided sample (sample_english.wav) is for testing. Replace it with your own audio.\n",
        "## Model Adjustments :\n",
        "##For better accuracy,\n",
        "#### use whisper.load_model(\"large-v2\").\n",
        "##For dialectal Arabic,\n",
        "####fine-tune aubmindlab/aragpt2 on dialect-specific data."
      ],
      "metadata": {
        "id": "osClrQdmXWcK"
      }
    }
  ]
}